{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ace41c03-dfa3-4cb6-88bc-bcaa72cfdc85",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd4ac0d-886b-44a0-b794-ef7c4d867a3e",
   "metadata": {},
   "source": [
    "## 基础下载模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "572e506f-169a-4a07-95a8-40d89fc39104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import shutil\n",
    "import requests\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "from typing import IO\n",
    "from pathlib import Path\n",
    "\n",
    "cache_dir = Path.home() / '.mindspore_examples'\n",
    "\n",
    "def http_get(url: str, temp_file:IO):\n",
    "    req = requests.get(url, stream=True)\n",
    "    content_length = req.headers.get('Content-Length')\n",
    "    total = int(content_length) if content_length is not None else None\n",
    "    progress = tqdm(unit='B', total=total)\n",
    "    for chunk in req.iter_content(chunk_size=1024):\n",
    "        if chunk:\n",
    "            progress.update(len(chunk))\n",
    "            temp_file.write(chunk)\n",
    "    progress.close()\n",
    "\n",
    "def download(file_name:str, url: str):\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir)\n",
    "    cache_path = os.path.join(cache_dir, file_name)\n",
    "    cache_exist = os.path.exists(cache_path)\n",
    "    if not cache_exist:\n",
    "        with tempfile.NamedTemporaryFile() as temp_file:\n",
    "            http_get(url, temp_file)\n",
    "            temp_file.flush()\n",
    "            temp_file.seek(0)\n",
    "            logging.info(f\"copying {temp_file.name} to cache at {cache_path}\")\n",
    "            with open(cache_path, 'wb') as cache_file:\n",
    "                shutil.copyfileobj(temp_file, cache_file)\n",
    "    return cache_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b146320f-206d-4ce3-92b8-19c71d23e3d9",
   "metadata": {},
   "source": [
    "## 加载IMDB数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f260663-5525-4831-ad5b-b24cdc2ee07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import six\n",
    "import string\n",
    "import tarfile\n",
    "\n",
    "class IMDBData():\n",
    "    label_map = {\n",
    "        \"pos\": 1,\n",
    "        \"neg\": 0\n",
    "    }\n",
    "    def __init__(self, path, mode=\"train\"):\n",
    "        self.mode = mode\n",
    "        self.path = path\n",
    "        self.docs, self.labels = [], []\n",
    "\n",
    "        self._load(\"pos\")\n",
    "        self._load(\"neg\")\n",
    "\n",
    "    def _load(self, label):\n",
    "        pattern = re.compile(r\"aclImdb/{}/{}/.*\\.txt$\".format(self.mode, label))\n",
    "        # load tarfile to memory\n",
    "        with tarfile.open(self.path) as tarf:\n",
    "            tf = tarf.next()\n",
    "            while tf is not None:\n",
    "                if bool(pattern.match(tf.name)):\n",
    "                    self.docs.append(str(tarf.extractfile(tf).read().rstrip(six.b(\"\\n\\r\"))\n",
    "                        .translate(None, six.b(string.punctuation)).lower(\n",
    "                        )).split())\n",
    "                    self.labels.append([self.label_map[label]])\n",
    "                tf = tarf.next()               \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.docs[idx], self.labels[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb0df701-e3b5-46e3-968d-9d44a2796eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_path = download('aclImdb_v1.tar.gz', 'https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/aclImdb_v1.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e08908b9-4997-4c93-a1e1-d1573991d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train = IMDBData(imdb_path, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3edb4fa0-86fa-44c2-9c48-e514f964b436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imdb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbf93849-0061-41e3-b49e-0f6475c84f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.dataset as dataset\n",
    "\n",
    "def load_imdb(imdb_path):\n",
    "    imdb_extract_path = os.path.join(cache_dir, 'aclImdb')\n",
    "    if not os.path.exists(imdb_extract_path):\n",
    "        tar = tarfile.open(imdb_path)\n",
    "        tar.extractall(path=cache_dir)\n",
    "    imdb_train = dataset.GeneratorDataset(IMDBData(imdb_path, \"train\"), column_names=[\"text\", \"label\"])\n",
    "    imdb_test = dataset.GeneratorDataset(IMDBData(imdb_path, \"test\"), column_names=[\"text\", \"label\"])\n",
    "    return imdb_train, imdb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2471d850-6770-4308-bcbe-40b5bbd919db",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train, imdb_test = load_imdb(imdb_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ee5b20-7547-4ca1-83fa-6ee083cc65a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 下载预训练词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34ca0aee-7deb-45ea-8231-2be5f9c2e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = download('glove.6B.zip', 'https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/glove.6B.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "519a863f-4053-4c20-93e2-b0acac829372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "def load_glove(glove_path):\n",
    "    glove_100d_path = os.path.join(cache_dir, 'glove.6B.100d.txt')\n",
    "    if not os.path.exists(glove_100d_path):\n",
    "        glove_zip = zipfile.ZipFile(glove_path)\n",
    "        glove_zip.extractall(cache_dir)\n",
    "\n",
    "    embeddings = []\n",
    "    tokens = []\n",
    "    with open(glove_100d_path, encoding='utf-8') as gf:\n",
    "        for glove in gf:\n",
    "            word, embedding = glove.split(maxsplit=1)\n",
    "            tokens.append(word)\n",
    "            embeddings.append(np.fromstring(embedding, dtype=np.float32, sep=' '))\n",
    "    # add embeddings for <unk> and <pad>\n",
    "    embeddings.append(np.random.rand(100))\n",
    "    embeddings.append(np.zeros((100,), np.float32))\n",
    "    \n",
    "    vocab = dataset.text.Vocab.from_list(tokens, special_tokens=[\"<unk>\", \"<pad>\"], special_first=False)\n",
    "    embeddings = np.array(embeddings).astype(np.float32)\n",
    "    return vocab, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8337d52c-aa9c-4316-919e-a901899a78bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, embeddings = load_glove(glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b12e8554-496c-4f35-a0bc-67a3f60ff488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
       "        -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
       "         0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
       "        -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
       "         0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
       "        -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
       "         0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
       "         0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
       "        -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
       "        -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
       "        -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
       "        -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
       "        -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
       "        -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
       "        -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
       "         0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
       "        -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ], dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = vocab.tokens_to_ids('the')\n",
    "embedding = embeddings[idx]\n",
    "idx, embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186eba95-4501-4427-9079-f5202f06e989",
   "metadata": {},
   "source": [
    "## 数据集预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a9451b7-e30b-4039-9955-40daac18b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore\n",
    "lookup_op = dataset.text.Lookup(vocab, unknown_token='<unk>')\n",
    "pad_op = dataset.transforms.c_transforms.PadEnd([500], pad_value=vocab.tokens_to_ids('<pad>'))\n",
    "type_cast_op = dataset.transforms.c_transforms.TypeCast(mindspore.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f8cdc63-8460-4432-baa7-297acb17dd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:37:40.897.612 [mindspore/dataset/engine/datasets.py:1064] Dataset is shuffled before split.\n"
     ]
    }
   ],
   "source": [
    "imdb_train = imdb_train.map(operations=[lookup_op, pad_op],  input_columns=['text'])\n",
    "imdb_train = imdb_train.map(operations=[type_cast_op],  input_columns=['label'])\n",
    "\n",
    "imdb_train, imdb_valid = imdb_train.split([0.7, 0.3])\n",
    "\n",
    "imdb_test = imdb_test.map(operations=[lookup_op, pad_op],  input_columns=['text'])\n",
    "imdb_test = imdb_test.map(operations=[type_cast_op],  input_columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b9988cf-0dfb-424d-930a-1dc2f1ff9176",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train = imdb_train.batch(64, drop_remainder=True)\n",
    "imdb_valid = imdb_valid.batch(64, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2be28663-85b3-4464-a8d0-dbe2ef6001ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "import mindspore.numpy as mnp\n",
    "import mindspore.ops as ops\n",
    "from mindspore import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0f1e26d-1b7c-4d50-947d-4fdda527b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Cell):\n",
    "    def __init__(self, embeddings, hidden_dim, output_dim, n_layers,\n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        vocab_size, embedding_dim = embeddings.shape\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, embedding_table=Tensor(embeddings), padding_idx=pad_idx)\n",
    "        self.rnn = nn.LSTM(embedding_dim,\n",
    "                           hidden_dim,\n",
    "                           num_layers=n_layers,\n",
    "                           bidirectional=bidirectional,\n",
    "                           dropout=dropout,\n",
    "                           batch_first=True)\n",
    "        self.fc = nn.Dense(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(1 - dropout)\n",
    "        self.sigmoid = ops.Sigmoid()\n",
    "\n",
    "    def construct(self, inputs):\n",
    "        # inputs: (batch, seq_length)\n",
    "        embedded = self.dropout(self.embedding(inputs))\n",
    "        # embedded: (batch, seq_length, embedding_dim)\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        #outputs: (batch, seq_length, hidden_dim * num_directions)\n",
    "        #hidden: (num_layers * num_directions, batch_size, hidden_dim)\n",
    "        #cell: (num_layers * num_directions, batch_size, hidden_dim)\n",
    "        hidden = self.dropout(mnp.concatenate((hidden[-2,:,:], hidden[-1,:,:]), axis = 1))\n",
    "        output = self.fc(hidden)\n",
    "        return self.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "591b1301-e9e3-44eb-a88b-09d2e807f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "output_size = 1\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.5\n",
    "pad_idx = vocab.tokens_to_ids('<pad>')\n",
    "\n",
    "net = RNN(embeddings, hidden_size, output_size, num_layers, bidirectional, dropout, pad_idx)\n",
    "loss = nn.BCELoss(reduction='mean')\n",
    "net_with_loss = nn.WithLossCell(net, loss)\n",
    "optimizer = nn.Adam(net.trainable_params())\n",
    "train_one_step = nn.TrainOneStepCell(net_with_loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5479830-8370-484d-a6ae-2a5985ab43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataset, epoch=0):\n",
    "    model.set_train()\n",
    "    total = train_dataset.get_dataset_size()\n",
    "    loss_total = 0\n",
    "    step_total = 0\n",
    "    with tqdm(total=total) as t:\n",
    "        t.set_description('Epoch %i' % epoch)\n",
    "        for i in train_dataset.create_tuple_iterator():\n",
    "            loss = model(*i)\n",
    "            loss_total += loss.asnumpy()\n",
    "            step_total += 1\n",
    "            t.set_postfix(loss=loss_total/step_total)\n",
    "            t.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "028a0b84-deee-4d1b-a1ad-a6ad515fd22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = np.around(preds)\n",
    "    correct = (rounded_preds == y).astype(np.float32) #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78bfafbc-3a10-4aab-b9bb-3189f84bc81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataset, criterion, epoch=0):\n",
    "    total = test_dataset.get_dataset_size()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    step_total = 0\n",
    "    model.set_train(False)\n",
    "\n",
    "    iterator = test_dataset.create_tuple_iterator()\n",
    "    with tqdm(total=total) as t:\n",
    "        t.set_description('Epoch %i' % epoch)\n",
    "        for i in test_dataset.create_tuple_iterator():\n",
    "            predictions = model(i[0])\n",
    "            loss = criterion(predictions, i[1])\n",
    "            epoch_loss += loss.asnumpy()\n",
    "\n",
    "            acc = binary_accuracy(predictions.asnumpy(), i[1].asnumpy())\n",
    "            epoch_acc += acc\n",
    "\n",
    "            step_total += 1\n",
    "            t.set_postfix(loss=epoch_loss/step_total, acc=epoch_acc/step_total)\n",
    "            t.update(1)\n",
    "\n",
    "    return epoch_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "851ec476-ca3a-439c-95db-55312dbda7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████████████████████████████| 273/273 [00:51<00:00,  5.28it/s, loss=0.675]\n",
      "Epoch 0: 100%|███████████████████████████████| 117/117 [00:44<00:00,  2.65it/s, acc=0.572, loss=0.674]\n",
      "Epoch 1: 100%|██████████████████████████████████████████| 273/273 [00:44<00:00,  6.14it/s, loss=0.642]\n",
      "Epoch 1: 100%|███████████████████████████████| 117/117 [00:43<00:00,  2.71it/s, acc=0.703, loss=0.574]\n",
      "Epoch 2: 100%|██████████████████████████████████████████| 273/273 [00:44<00:00,  6.13it/s, loss=0.473]\n",
      "Epoch 2: 100%|███████████████████████████████| 117/117 [00:43<00:00,  2.72it/s, acc=0.844, loss=0.363]\n",
      "Epoch 3: 100%|██████████████████████████████████████████| 273/273 [00:44<00:00,  6.14it/s, loss=0.332]\n",
      "Epoch 3: 100%|███████████████████████████████| 117/117 [00:42<00:00,  2.73it/s, acc=0.901, loss=0.248]\n",
      "Epoch 4: 100%|███████████████████████████████████████████| 273/273 [00:44<00:00,  6.10it/s, loss=0.28]\n",
      "Epoch 4: 100%|███████████████████████████████| 117/117 [00:43<00:00,  2.72it/s, acc=0.932, loss=0.191]\n"
     ]
    }
   ],
   "source": [
    "from mindspore import save_checkpoint\n",
    "\n",
    "num_epochs = 5\n",
    "best_valid_loss = float('inf')\n",
    "ckpt_file_name = os.path.join(cache_dir, 'sentiment-analysis.ckpt')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(train_one_step, imdb_train, epoch)\n",
    "    valid_loss = evaluate(net, imdb_valid, loss, epoch)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        save_checkpoint(net, ckpt_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccc7b0d-9055-4cab-9b6d-46bc0b06f60a",
   "metadata": {},
   "source": [
    "## 加载Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d477ec12-04ff-488b-8d31-ae82e5e9be2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.931.281 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(400002, 100), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.937.247 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1024, 100), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.938.503 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1024, 100), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.939.863 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1024, 512), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.941.203 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1024, 512), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.942.337 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1024, 256), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.943.432 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1024, 256), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.944.512 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1024, 256), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.945.643 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1024, 256), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.946.580 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1024,), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.947.494 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1024,), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.948.307 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1024,), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.949.179 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1024,), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.950.026 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1024,), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.950.934 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1024,), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.951.863 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1024,), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.952.768 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1024,), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.953.688 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1, 512), dtype=Float32, requires_grad=True)'.\n",
      "[WARNING] ME(10533:140346481461056,MainProcess):2022-02-21-11:45:09.954.598 [mindspore/common/parameter.py:338] The parameter definition is deprecated.\n",
      "Please set a unique name for the parameter 'Parameter (name=Parameter, shape=(1,), dtype=Float32, requires_grad=True)'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "\n",
    "param_dict = load_checkpoint(ckpt_file_name)\n",
    "load_param_into_net(net, param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3969ddd-ef79-433b-8f3a-dafaaf0a0540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|███████████████████████████████| 391/391 [00:35<00:00, 11.11it/s, acc=0.868, loss=0.337]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.33658065644981305"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_test = imdb_test.batch(64)\n",
    "evaluate(net, imdb_test, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5be370-edc3-4453-802a-f5eea34cd77f",
   "metadata": {},
   "source": [
    "## 自定义输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b35902c6-84a3-4879-8fde-2d6f322f49eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, vocab, sentence):\n",
    "    model.set_train(False)\n",
    "    tokenized = sentence.lower().split()\n",
    "    indexed = vocab.tokens_to_ids(tokenized)\n",
    "    tensor = mindspore.Tensor(indexed, mindspore.int32)\n",
    "    tensor = tensor.expand_dims(0)\n",
    "    prediction = model(tensor)\n",
    "    return prediction.asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f6ea007-96a9-4b7c-9f5c-59329c0c7de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02964271]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, \"This film is terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6d9108e-8151-4ccc-a433-b33f437f1c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9793879]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, \"This film is great\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
