{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36818c3e-b7c8-4c4d-a7ac-2b3820fb23d2",
   "metadata": {},
   "source": [
    "# Seq2Seq模型实现文本翻译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b761ff8-3235-4d65-994c-ad779ed3c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {\n",
    "    'train': 'http://www.quest.dcs.shef.ac.uk/wmt16_files_mmt/training.tar.gz',\n",
    "    'valid': 'http://www.quest.dcs.shef.ac.uk/wmt16_files_mmt/validation.tar.gz',\n",
    "    'test': 'http://www.quest.dcs.shef.ac.uk/wmt17_files_mmt/mmt_task1_test2016.tar.gz'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d773567c-8950-4cc9-8933-68d8718e2bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee6992c-d673-40e0-a88f-1780dafe71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import six\n",
    "import string\n",
    "import tarfile\n",
    "\n",
    "class Multi30K():\n",
    "    \"\"\"Multi30K数据集加载器\n",
    "    \n",
    "    加载IMDB数据集并处理为一个Python迭代对象。\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, path):\n",
    "        pass\n",
    "        \n",
    "    def _load(self, label):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.docs[idx], self.labels[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ffd9d-2302-42d6-8cad-ddfe45060fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iterator():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def split(self, shuffle=True):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df1cc28-63f3-4779-9bd5-97a214fc8f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import shutil\n",
    "import requests\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "from typing import IO\n",
    "from pathlib import Path\n",
    "\n",
    "# 指定保存路径为 `home_path/.mindspore_examples`\n",
    "cache_dir = Path.home() / '.mindspore_examples'\n",
    "\n",
    "def http_get(url: str, temp_file:IO):\n",
    "    \"\"\"使用requests库下载数据，并使用tqdm库进行流程可视化\"\"\"\n",
    "    req = requests.get(url, stream=True)\n",
    "    content_length = req.headers.get('Content-Length')\n",
    "    total = int(content_length) if content_length is not None else None\n",
    "    progress = tqdm(unit='B', total=total)\n",
    "    for chunk in req.iter_content(chunk_size=1024):\n",
    "        if chunk:\n",
    "            progress.update(len(chunk))\n",
    "            temp_file.write(chunk)\n",
    "    progress.close()\n",
    "\n",
    "def download(file_name:str, url: str):\n",
    "    \"\"\"下载数据并存为指定名称\"\"\"\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir)\n",
    "    cache_path = os.path.join(cache_dir, file_name)\n",
    "    cache_exist = os.path.exists(cache_path)\n",
    "    if not cache_exist:\n",
    "        with tempfile.NamedTemporaryFile() as temp_file:\n",
    "            http_get(url, temp_file)\n",
    "            temp_file.flush()\n",
    "            temp_file.seek(0)\n",
    "            logging.info(f\"copying {temp_file.name} to cache at {cache_path}\")\n",
    "            with open(cache_path, 'wb') as cache_file:\n",
    "                shutil.copyfileobj(temp_file, cache_file)\n",
    "    return cache_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5fdb130-1958-4f6f-85ac-e737c6afb63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1207136/1207136 [00:03<00:00, 341907.63B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/lvyufeng/.mindspore_examples/train.tar.gz'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download('train.tar.gz', urls['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4b5270d-bb6a-499f-b4e5-da6bb66730e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "f = tarfile.open('/home/lvyufeng/.mindspore_examples/train.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db3a33dd-ff7a-4166-9c1d-0b85bbdc4b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TarInfo 'train.de' at 0x7f0d1607b600>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = f.next()\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a3d730-ce22-417c-b340-c3c2b4367742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(dataset):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f42f239-12db-401d-90e7-ab3e61aea880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "import mindspore.numpy as mnp\n",
    "\n",
    "class Encoder(nn.Cell):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\n",
    "        self.fc = nn.Dense(enc_hid_dim * 2, dec_hid_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(1-dropout)\n",
    "        \n",
    "    def construct(self, src, src_len):\n",
    "        #src = [src len, batch size]\n",
    "        #src_len = [batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "                        \n",
    "        outputs, hidden = self.rnn(embedded, seq_length=src_len)\n",
    "                                 \n",
    "        #outputs = [src len, batch size, hid dim * num directions]\n",
    "        #hidden = [n layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        #outputs are always from the last layer\n",
    "        \n",
    "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
    "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
    "        \n",
    "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
    "        #  encoder RNNs fed through a linear layer\n",
    "        hidden = ops.tanh(self.fc(mnp.concatenate((hidden[-2,:,:], hidden[-1,:,:]), axis = 1)))\n",
    "        \n",
    "        #outputs = [src len, batch size, enc hid dim * 2]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef553979-aee8-4d24-9a40-9beae9b79137",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Cell):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Dense((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Dense(dec_hid_dim, 1, bias = False)\n",
    "        \n",
    "    def construct(self, hidden, encoder_outputs, mask):\n",
    "        \n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        #repeat decoder hidden state src_len times\n",
    "        hidden = hidden.expand_dims(1).tile(1, src_len, 1)\n",
    "  \n",
    "        encoder_outputs = encoder_outputs.transpose(1, 0, 2)\n",
    "        \n",
    "        #hidden = [batch size, src len, dec hid dim]\n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        energy = ops.tanh(self.attn(mnp.concatenate((hidden, encoder_outputs), axis = 2))) \n",
    "        \n",
    "        #energy = [batch size, src len, dec hid dim]\n",
    "\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        #attention = [batch size, src len]\n",
    "        \n",
    "        attention = attention.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        return ops.Softmax(1)(attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b469f89-2f24-4b84-96d2-987e188da7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Cell):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        self.fc_out = nn.Dense((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(1-dropout)\n",
    "        \n",
    "    def forward(self, inputs, hidden, encoder_outputs, mask):\n",
    "             \n",
    "        #input = [batch size]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        #mask = [batch size, src len]\n",
    "        \n",
    "        inputs = inputs.expand_dims(0)\n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        a = self.attention(hidden, encoder_outputs, mask)\n",
    "                \n",
    "        #a = [batch size, src len]\n",
    "        \n",
    "        a = a.expand_dims(1)\n",
    "        \n",
    "        #a = [batch size, 1, src len]\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.transpose(1, 0, 2)\n",
    "        \n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        weighted = ops.BatchMatMul()(a, encoder_outputs)\n",
    "        \n",
    "        #weighted = [batch size, 1, enc hid dim * 2]\n",
    "        \n",
    "        weighted = weighted.transpose(1, 0, 2)\n",
    "        \n",
    "        #weighted = [1, batch size, enc hid dim * 2]\n",
    "        \n",
    "        rnn_input = mnp.concatenate((embedded, weighted), axis = 2)\n",
    "        \n",
    "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
    "            \n",
    "        output, hidden = self.rnn(rnn_input, hidden.expand_dims(0))\n",
    "        \n",
    "        #output = [seq len, batch size, dec hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
    "        \n",
    "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        #output = [1, batch size, dec hid dim]\n",
    "        #hidden = [1, batch size, dec hid dim]\n",
    "        #this also means that output == hidden\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        prediction = self.fc_out(mnp.concatenate((output, weighted, embedded), axis = 1))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden.squeeze(0), a.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b236a48-d545-49fa-aff6-81d99060fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Cell):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def create_mask(self, src):\n",
    "        mask = (src != self.src_pad_idx).swapaxes(1, 0)\n",
    "        return mask\n",
    "        \n",
    "    def construct(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #src_len = [batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "                    \n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
    "                \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        mask = self.create_mask(src)\n",
    "\n",
    "        #mask = [batch size, src len]\n",
    "                \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden state, all encoder hidden states \n",
    "            #  and mask\n",
    "            #receive output tensor (predictions) and new hidden state\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            \n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
