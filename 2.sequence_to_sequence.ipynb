{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36818c3e-b7c8-4c4d-a7ac-2b3820fb23d2",
   "metadata": {},
   "source": [
    "# Seq2Seq模型实现文本翻译"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d0866a-718e-48a6-8bf2-2415cd9f0fd3",
   "metadata": {},
   "source": [
    "## 概述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b761ff8-3235-4d65-994c-ad779ed3c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {\n",
    "    'train': 'http://www.quest.dcs.shef.ac.uk/wmt16_files_mmt/training.tar.gz',\n",
    "    'valid': 'http://www.quest.dcs.shef.ac.uk/wmt16_files_mmt/validation.tar.gz',\n",
    "    'test': 'http://www.quest.dcs.shef.ac.uk/wmt17_files_mmt/mmt_task1_test2016.tar.gz'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ec68c-8302-4229-8aa3-3e7e4429d535",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b58840-b2fb-49b2-8440-a27417256037",
   "metadata": {},
   "source": [
    "### 词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d773567c-8950-4cc9-8933-68d8718e2bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, word_count_dict, min_freq=1, special_tokens=['<unk>', '<pad>', '<bos>', '<eos>']):\n",
    "        self.word2idx = {}\n",
    "        for idx, tok in enumerate(special_tokens):\n",
    "            self.word2idx[tok] = idx\n",
    "\n",
    "        filted_dict = {w: c for w, c in word_count_dict.items() if c >= min_freq}\n",
    "        for w, _ in filted_dict.items():\n",
    "            self.word2idx[w] = len(self.word2idx)\n",
    "        \n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "\n",
    "        self.bos_idx = self.word2idx['<bos>']\n",
    "        self.eos_idx = self.word2idx['<eos>']\n",
    "        self.pad_idx = self.word2idx['<pad>']\n",
    "        self.unk_idx = self.word2idx['<unk>']\n",
    "\n",
    "    def _word2idx(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            return self.unk_idx\n",
    "        return self.word2idx[word]\n",
    "    \n",
    "    def _idx2word(self, idx):\n",
    "        if idx not in self.idx2word:\n",
    "            raise ValueError('input index is not in vocabulary.')\n",
    "        return self.idx2word[idx]\n",
    "    \n",
    "    def encode(self, word_or_list):\n",
    "        if isinstance(word_or_list, list):\n",
    "            return [self._word2idx(i) for i in word_or_list]\n",
    "        return self._word2idx(word_or_list)\n",
    "    \n",
    "    def decode(self, idx_or_list):\n",
    "        if isinstance(idx_or_list, list):\n",
    "            return [self._idx2word(i) for i in idx_or_list]\n",
    "        return self._idx2word(idx_or_list)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c0a1ee-0306-47ff-8074-1c83c3dc9678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = {'a':20, 'b':10, 'c':1, 'd':2}\n",
    "\n",
    "vocab = Vocab(word_count, min_freq=2)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb98795-10e6-46a1-bdff-f29659111780",
   "metadata": {},
   "source": [
    "### Multi30K数据集\n",
    "\n",
    "> pip install spacy\n",
    "\n",
    "> python -m spacy download de_core_news_sm\n",
    "\n",
    "> python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee6992c-d673-40e0-a88f-1780dafe71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import six\n",
    "import string\n",
    "import tarfile\n",
    "import spacy\n",
    "from functools import partial\n",
    "\n",
    "class Multi30K():\n",
    "    \"\"\"Multi30K数据集加载器\n",
    "    \n",
    "    加载IMDB数据集并处理为一个Python迭代对象。\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, path):\n",
    "        self.data = self._load(path)\n",
    "        \n",
    "    def _load(self, path):\n",
    "        def tokenize(text, spacy_lang):\n",
    "            text = text.rstrip()\n",
    "            return [tok.text.lower() for tok in spacy_lang.tokenizer(text)]\n",
    "        \n",
    "        tokenize_de = partial(tokenize, spacy_lang=spacy.load('de_core_news_sm'))\n",
    "        tokenize_en = partial(tokenize, spacy_lang=spacy.load('en_core_web_sm'))\n",
    "        \n",
    "        tarf = tarfile.open(path)\n",
    "        members = {i.name.split('.')[-1]: i for i in tarf.getmembers()}\n",
    "        de = tarf.extractfile(members['de']).readlines()[:-1]\n",
    "        de = [tokenize_de(i.decode()) for i in de]\n",
    "        en = tarf.extractfile(members['en']).readlines()[:-1]\n",
    "        en = [tokenize_en(i.decode()) for i in en]\n",
    "\n",
    "        return list(zip(de, en))\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdab55c7-97f0-480f-b01b-dd7069bdd633",
   "metadata": {},
   "source": [
    "### 数据迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1ffd9d-2302-42d6-8cad-ddfe45060fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore\n",
    "\n",
    "class Iterator():\n",
    "    def __init__(self, dataset, de_vocab, en_vocab, batch_size, max_len=32, drop_reminder=False):\n",
    "        self.dataset = dataset\n",
    "        self.de_vocab = de_vocab\n",
    "        self.en_vocab = en_vocab\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.max_len = max_len\n",
    "        self.drop_reminder = drop_reminder\n",
    "\n",
    "        length = len(self.dataset) // batch_size \n",
    "        self.len = length if drop_reminder else length + 1\n",
    "    \n",
    "    def __call__(self):\n",
    "        def pad(idx_list, vocab, max_len):\n",
    "            idx_pad_list, idx_len = [], []\n",
    "            # max_len = max([len(i) for i in idx_list]) + 2\n",
    "            for i in idx_list:\n",
    "                if len(i) > max_len - 2:\n",
    "                    idx_pad_list.append(\n",
    "                        [vocab.bos_idx] + i[:max_len-2] + [vocab.eos_idx]\n",
    "                    )\n",
    "                    idx_len.append(max_len)\n",
    "                else:\n",
    "                    idx_pad_list.append(\n",
    "                        [vocab.bos_idx] + i + [vocab.eos_idx] + [vocab.pad_idx] * (max_len - len(i) - 2)\n",
    "                    )\n",
    "                    idx_len.append(len(i) + 2)\n",
    "            return idx_pad_list, idx_len\n",
    "\n",
    "        def sort_by_length(src, trg):\n",
    "            data = zip(src, trg)\n",
    "            data = sorted(data, key=lambda t: len(t[0]), reverse=True)\n",
    "            return zip(*list(data))\n",
    "            \n",
    "        def encode_and_pad(batch_data, max_len):\n",
    "            src_data, trg_data = zip(*batch_data)\n",
    "            src_idx = [self.de_vocab.encode(i) for i in src_data]\n",
    "            trg_idx = [self.en_vocab.encode(i) for i in trg_data]\n",
    "            \n",
    "            src_idx, trg_idx = sort_by_length(src_idx, trg_idx)\n",
    "            src_idx_pad, src_len = pad(src_idx, de_vocab, max_len)\n",
    "            trg_idx_pad, _ = pad(trg_idx, en_vocab, max_len)\n",
    "            \n",
    "            return src_idx_pad, src_len, trg_idx_pad\n",
    "        \n",
    "        for i in range(self.len):\n",
    "            if i == self.len - 1 and not self.drop_reminder:\n",
    "                batch_data = self.dataset[i * self.batch_size:]\n",
    "            else:\n",
    "                batch_data = self.dataset[i * self.batch_size: (i+1) * self.batch_size]\n",
    "            \n",
    "            src_idx, src_len, trg_idx = encode_and_pad(batch_data, self.max_len)\n",
    "            yield mindspore.Tensor(src_idx, mindspore.int32), \\\n",
    "                mindspore.Tensor(src_len, mindspore.int32), \\\n",
    "                mindspore.Tensor(trg_idx, mindspore.int32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397d4f5f-bd01-43a9-8c46-1457ca702ef0",
   "metadata": {},
   "source": [
    "### 数据下载模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5df1cc28-63f3-4779-9bd5-97a214fc8f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import shutil\n",
    "import requests\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "from typing import IO\n",
    "from pathlib import Path\n",
    "\n",
    "# 指定保存路径为 `home_path/.mindspore_examples`\n",
    "cache_dir = Path.home() / '.mindspore_examples'\n",
    "\n",
    "def http_get(url: str, temp_file:IO):\n",
    "    \"\"\"使用requests库下载数据，并使用tqdm库进行流程可视化\"\"\"\n",
    "    req = requests.get(url, stream=True)\n",
    "    content_length = req.headers.get('Content-Length')\n",
    "    total = int(content_length) if content_length is not None else None\n",
    "    progress = tqdm(unit='B', total=total)\n",
    "    for chunk in req.iter_content(chunk_size=1024):\n",
    "        if chunk:\n",
    "            progress.update(len(chunk))\n",
    "            temp_file.write(chunk)\n",
    "    progress.close()\n",
    "\n",
    "def download(file_name:str, url: str):\n",
    "    \"\"\"下载数据并存为指定名称\"\"\"\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir)\n",
    "    cache_path = os.path.join(cache_dir, file_name)\n",
    "    cache_exist = os.path.exists(cache_path)\n",
    "    if not cache_exist:\n",
    "        with tempfile.NamedTemporaryFile() as temp_file:\n",
    "            http_get(url, temp_file)\n",
    "            temp_file.flush()\n",
    "            temp_file.seek(0)\n",
    "            logging.info(f\"copying {temp_file.name} to cache at {cache_path}\")\n",
    "            with open(cache_path, 'wb') as cache_file:\n",
    "                shutil.copyfileobj(temp_file, cache_file)\n",
    "    return cache_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5fdb130-1958-4f6f-85ac-e737c6afb63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(urls):\n",
    "    train_path = download('train.tar.gz', urls['train'])\n",
    "    valid_path = download('valid.tar.gz', urls['valid'])    \n",
    "    test_path = download('test.tar.gz', urls['test'])\n",
    "    \n",
    "    return Multi30K(train_path), Multi30K(valid_path), Multi30K(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4b5270d-bb6a-499f-b4e5-da6bb66730e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = download_dataset(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db3a33dd-ff7a-4166-9c1d-0b85bbdc4b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ein', 'mann', 'mit', 'einem', 'orangefarbenen', 'hut', ',', 'der', 'etwas', 'anstarrt', '.'] ['a', 'man', 'in', 'an', 'orange', 'hat', 'starring', 'at', 'something', '.']\n"
     ]
    }
   ],
   "source": [
    "for de, en in test_dataset:\n",
    "    print(de, en)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aabc6a1-7f11-412a-a5f8-13fe47312914",
   "metadata": {},
   "source": [
    "### 词典构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9a3d730-ce22-417c-b340-c3c2b4367742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "\n",
    "def build_vocab(dataset):\n",
    "    de_words, en_words = [], []\n",
    "    for de, en in dataset:\n",
    "        de_words.extend(de)\n",
    "        en_words.extend(en)\n",
    "        \n",
    "    de_count_dict = OrderedDict(sorted(Counter(de_words).items(), key=lambda t: t[1], reverse=True))\n",
    "    en_count_dict = OrderedDict(sorted(Counter(en_words).items(), key=lambda t: t[1], reverse=True))\n",
    "    \n",
    "    return Vocab(de_count_dict, min_freq=2), Vocab(en_count_dict, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05ae1078-7280-44af-9818-24ee148e815d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7853"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_vocab, en_vocab = build_vocab(train_dataset)\n",
    "len(de_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6e115a-8cfd-4f45-982b-8c9d6d76167a",
   "metadata": {},
   "source": [
    "## 模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebf342f-074f-445e-82e4-2b8a9a111ce3",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f42f239-12db-401d-90e7-ab3e61aea880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "import mindspore.numpy as mnp\n",
    "\n",
    "class Encoder(nn.Cell):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True).to_float(compute_dtype)\n",
    "        self.fc = nn.Dense(enc_hid_dim * 2, dec_hid_dim).to_float(compute_dtype)\n",
    "\n",
    "        self.dropout = nn.Dropout(1-dropout)\n",
    "        \n",
    "    def construct(self, src, src_len):\n",
    "        #src = [src len, batch size]\n",
    "        #src_len = [batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "                        \n",
    "        outputs, hidden = self.rnn(embedded, seq_length=src_len)\n",
    "                                 \n",
    "        #outputs = [src len, batch size, hid dim * num directions]\n",
    "        #hidden = [n layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        #outputs are always from the last layer\n",
    "        \n",
    "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
    "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
    "        \n",
    "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
    "        #  encoder RNNs fed through a linear layer\n",
    "        hidden = ops.tanh(self.fc(mnp.concatenate((hidden[-2,:,:], hidden[-1,:,:]), axis = 1)))\n",
    "        \n",
    "        #outputs = [src len, batch size, enc hid dim * 2]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        # print(hidden)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6102e81b-0095-464a-9f2b-32daf2f62397",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef553979-aee8-4d24-9a40-9beae9b79137",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Cell):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Dense((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim).to_float(compute_dtype)\n",
    "        self.v = nn.Dense(dec_hid_dim, 1, has_bias = False).to_float(compute_dtype)\n",
    "        \n",
    "    def construct(self, hidden, encoder_outputs, mask):\n",
    "        \n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        #repeat decoder hidden state src_len times\n",
    "        hidden = mnp.tile(hidden.expand_dims(1), (1, src_len, 1))\n",
    "  \n",
    "        encoder_outputs = encoder_outputs.transpose(1, 0, 2)\n",
    "        \n",
    "        #hidden = [batch size, src len, dec hid dim]\n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        energy = ops.tanh(self.attn(mnp.concatenate((hidden, encoder_outputs), axis = 2))) \n",
    "        \n",
    "        #energy = [batch size, src len, dec hid dim]\n",
    "\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        #attention = [batch size, src len]\n",
    "        \n",
    "        attention = attention.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        return ops.Softmax(1)(attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f00e1e-976a-4ce5-8709-4f256b805bca",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b469f89-2f24-4b84-96d2-987e188da7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Cell):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim).to_float(compute_dtype)\n",
    "        self.fc_out = nn.Dense((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim).to_float(compute_dtype)\n",
    "        self.dropout = nn.Dropout(1-dropout)\n",
    "        \n",
    "    def construct(self, inputs, hidden, encoder_outputs, mask):\n",
    "             \n",
    "        #input = [batch size]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        #mask = [batch size, src len]\n",
    "        \n",
    "        inputs = inputs.expand_dims(0)\n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(inputs))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        a = self.attention(hidden, encoder_outputs, mask)\n",
    "                \n",
    "        #a = [batch size, src len]\n",
    "        \n",
    "        a = a.expand_dims(1)\n",
    "        \n",
    "        #a = [batch size, 1, src len]\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.transpose(1, 0, 2)\n",
    "        \n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        weighted = ops.BatchMatMul()(a, encoder_outputs)\n",
    "        \n",
    "        #weighted = [batch size, 1, enc hid dim * 2]\n",
    "        \n",
    "        weighted = weighted.transpose(1, 0, 2)\n",
    "        \n",
    "        #weighted = [1, batch size, enc hid dim * 2]\n",
    "        \n",
    "        rnn_input = mnp.concatenate((embedded, weighted), axis = 2)\n",
    "        \n",
    "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
    "            \n",
    "        output, hidden = self.rnn(rnn_input, hidden.expand_dims(0))\n",
    "        \n",
    "        #output = [seq len, batch size, dec hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
    "        \n",
    "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        #output = [1, batch size, dec hid dim]\n",
    "        #hidden = [1, batch size, dec hid dim]\n",
    "        #this also means that output == hidden\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        prediction = self.fc_out(mnp.concatenate((output, weighted, embedded), axis = 1))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden.squeeze(0), a.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec697d7e-cdc9-46f5-ba83-373dcc963b16",
   "metadata": {},
   "source": [
    "### Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b236a48-d545-49fa-aff6-81d99060fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Seq2Seq(nn.Cell):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, teacher_forcing_ration):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ration\n",
    "        self.random = ops.UniformReal()\n",
    "        \n",
    "    def create_mask(self, src):\n",
    "        mask = (src != self.src_pad_idx).astype(mindspore.int32).swapaxes(1, 0)\n",
    "        return mask\n",
    "        \n",
    "    def construct(self, src, src_len, trg, trg_len=None):\n",
    "        #src = [src len, batch size]\n",
    "        #src_len = [batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "        if trg_len is None:\n",
    "            trg_len = trg.shape[0]\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = []\n",
    "        \n",
    "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
    "                \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        inputs = trg[0]\n",
    "        \n",
    "        mask = self.create_mask(src)\n",
    "\n",
    "        #mask = [batch size, src len]\n",
    "                \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden state, all encoder hidden states \n",
    "            #  and mask\n",
    "            #receive output tensor (predictions) and new hidden state\n",
    "            output, hidden, _ = self.decoder(inputs, hidden, encoder_outputs, mask)\n",
    "            # print(output)\n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs.append(output)\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "\n",
    "            if self.training:\n",
    "                #decide if we are going to use teacher forcing or not\n",
    "                teacher_force = self.random((1,)) < self.teacher_forcing_ratio\n",
    "                # teacher_force = random.random() < self.teacher_forcing_ratio\n",
    "                #if teacher forcing, use actual next token as next input\n",
    "                #if not, use predicted token\n",
    "                inputs = trg[t] if teacher_force else top1\n",
    "            else:\n",
    "                inputs = top1\n",
    "        \n",
    "        outputs = mnp.stack(outputs, axis=0)\n",
    "            \n",
    "        return outputs.astype(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8013b5-0c79-4555-91e1-e3e869865e32",
   "metadata": {},
   "source": [
    "## CrossEntropy损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a30b5af3-9a28-4bf6-9085-13e948470942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy(nn.Cell):\n",
    "    reduction_list = ['sum', 'mean', 'none']\n",
    "    def __init__(self, weight=None, ignore_index:int=-100, reduction:str='mean', label_smoothing:float=0.0):        \n",
    "        super().__init__()\n",
    "        if label_smoothing > 1.0 or label_smoothing < 0.0:\n",
    "            raise ValueError(f'label_smoothing value must in range [0.0, 1.0], '\n",
    "                             f'but get {label_smoothing}')\n",
    "        \n",
    "        if reduction not in self.reduction_list:\n",
    "            raise ValueError(f'Unsupported reduction {reduction}')\n",
    "        \n",
    "        self.weight = weight\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reduction = reduction\n",
    "        self.label_smoothing = label_smoothing\n",
    "\n",
    "    def construct(self, input, target):\n",
    "        return self._nll_loss(ops.LogSoftmax(1)(input), target, -1, self.weight, self.ignore_index, self.reduction, self.label_smoothing)\n",
    "\n",
    "    def _nll_loss(self, input, target, target_dim=-1, weight=None, ignore_index=None, reduction='none', label_smoothing=0.0):\n",
    "        if target.ndim == input.ndim - 1:\n",
    "            target = target.expand_dims(target_dim)\n",
    "        nll_loss = -ops.gather_d(input, target_dim, target)\n",
    "        smooth_loss = -input.sum(axis=target_dim, keepdims=True)\n",
    "        if weight is not None:\n",
    "            loss_weights = ops.gather(weight, target, 0)\n",
    "            nll_loss = nll_loss * loss_weights\n",
    "        else:\n",
    "            loss_weights = ops.ones_like(nll_loss)\n",
    "        if ignore_index is not None:\n",
    "            non_pad_mask = ops.equal(target, ignore_index)\n",
    "            nll_loss = nll_loss.masked_fill(non_pad_mask, 0.)\n",
    "            loss_weights = loss_weights.masked_fill(non_pad_mask, 0.)\n",
    "            smooth_loss = smooth_loss.masked_fill(non_pad_mask, 0.)\n",
    "        else:\n",
    "            nll_loss = nll_loss.squeeze(target_dim)\n",
    "            smooth_loss = smooth_loss.squeeze(target_dim)\n",
    "\n",
    "        if reduction == 'sum':\n",
    "            nll_loss = nll_loss.sum()\n",
    "            smooth_loss = smooth_loss.sum()\n",
    "        if reduction == 'mean':\n",
    "            nll_loss = nll_loss.sum() / loss_weights.sum()\n",
    "            smooth_loss = smooth_loss.mean()\n",
    "\n",
    "        eps_i = label_smoothing / input.shape[target_dim]\n",
    "        loss = (1. - label_smoothing) * nll_loss + eps_i * smooth_loss\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8644f5e0-5861-43f6-9f4d-0e532e744ae5",
   "metadata": {},
   "source": [
    "## 整图训练封装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b4d410-197e-4ae1-a00e-f85f953c9e14",
   "metadata": {},
   "source": [
    "### 自定义Loss求解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c59a2898-8917-4b9a-859b-2259cb8132fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqWithLoss(nn.Cell):\n",
    "    def __init__(self, network, loss):\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        self.loss = loss\n",
    "        \n",
    "    def construct(self, src, src_len, trg):\n",
    "        output = self.network(src, src_len, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        loss = self.loss(output, trg)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc97fe56-fbf2-4dc8-a645-77db0d0ba028",
   "metadata": {},
   "source": [
    "### 自定义梯度裁剪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e61223d-4a74-40f5-923f-30daa9d878cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import Tensor\n",
    "\n",
    "def clip_by_norm(clip, grad):\n",
    "    return nn.ClipByNorm()(grad, clip)\n",
    "\n",
    "class TrainOneStepCell(nn.TrainOneStepCell):\n",
    "    def __init__(self, network, optimizer, sens=1.0, clip=1.0):\n",
    "        super(TrainOneStepCell, self).__init__(network, optimizer, sens)\n",
    "        self.hyper_map = ops.HyperMap()\n",
    "        self.clip = Tensor(clip, mindspore.float32)\n",
    "        self.sens = Tensor(sens, mindspore.float32)\n",
    "\n",
    "    def construct(self, *inputs):\n",
    "        weights = self.weights\n",
    "        loss = self.network(*inputs)\n",
    "        grads = self.grad(self.network, weights)(*inputs, self.sens)\n",
    "        # 进行梯度截断\n",
    "        grads = self.hyper_map(ops.partial(clip_by_norm, self.clip), grads)\n",
    "        grads = self.grad_reducer(grads)\n",
    "        self.optimizer(grads)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2fe094-e6f5-42e9-b80b-27a829de4178",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48b01c54-cd1d-4164-86fe-61f5f2bc63fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(de_vocab)\n",
    "output_dim = len(en_vocab)\n",
    "enc_emb_dim = 256\n",
    "dec_emb_dim = 256\n",
    "enc_hid_dim = 512\n",
    "dec_hid_dim = 512\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5\n",
    "src_pad_idx = de_vocab.pad_idx\n",
    "trg_pad_idx = en_vocab.pad_idx\n",
    "\n",
    "compute_dtype = mindspore.float32\n",
    "dtype = mindspore.float32\n",
    "\n",
    "attn = Attention(enc_hid_dim, dec_hid_dim)\n",
    "encoder = Encoder(input_dim, enc_emb_dim, enc_hid_dim, dec_hid_dim, enc_dropout)\n",
    "decoder = Decoder(output_dim, dec_emb_dim, enc_hid_dim, dec_hid_dim, dec_dropout, attn)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, src_pad_idx, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "212d94bd-73d3-4b07-980b-7e5820625820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mindspore.common.initializer import Normal, Zero, initializer\n",
    "\n",
    "# def init_weights(m):\n",
    "#     for param in m.trainable_params():\n",
    "#         if 'weight' in param.name:\n",
    "#             param.set_data(initializer(Normal(), param.shape))\n",
    "#         else:\n",
    "#             param.set_data(initializer(Zero(), param.shape))\n",
    "\n",
    "# init_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4e46920-7731-430d-aeeb-47e6939078fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = CrossEntropy(ignore_index=trg_pad_idx)\n",
    "model_with_loss = Seq2SeqWithLoss(model, loss)\n",
    "optimizer = nn.Adam(model.trainable_params(), learning_rate=0.001)\n",
    "trainer = TrainOneStepCell(model_with_loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10633be1-47cc-4931-9f0e-3f1c917c636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_step(model, iterator, epoch=0):\n",
    "    model.set_train(True)\n",
    "    total = len(iterator)\n",
    "    loss_total = 0\n",
    "    step_total = 0\n",
    "    with tqdm(total=total) as t:\n",
    "        t.set_description('Epoch %i' % epoch)\n",
    "        for src, src_len, trg in iterator():\n",
    "            src = src.swapaxes(0, 1)\n",
    "            trg = trg.swapaxes(0, 1)\n",
    "            # print(src.shape, trg.shape)\n",
    "            loss = model(src, src_len, trg)\n",
    "            loss_total += loss.asnumpy()\n",
    "            step_total += 1\n",
    "            t.set_postfix(loss=loss_total/step_total)\n",
    "            t.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15748c19-10d2-4556-b6b1-5b1f4a09d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator):\n",
    "    model.set_train(False)\n",
    "    total = len(iterator)\n",
    "    loss_total = 0\n",
    "    step_total = 0\n",
    "    with tqdm(total=total) as t:\n",
    "        for src, src_len, trg in iterator():\n",
    "            src = src.swapaxes(0, 1)\n",
    "            trg = trg.swapaxes(0, 1)\n",
    "            loss = model(src, src_len, trg)\n",
    "            loss_total += loss.asnumpy()\n",
    "            step_total += 1\n",
    "            t.set_postfix(loss=loss_total/step_total)\n",
    "            t.update(1)\n",
    "    return loss_total / step_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd930931-e8ee-41c3-a63e-59972dd7cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = Iterator(train_dataset, de_vocab, en_vocab, batch_size=128, max_len=32, drop_reminder=True)\n",
    "valid_iterator = Iterator(valid_dataset, de_vocab, en_vocab, batch_size=128, max_len=32, drop_reminder=False)\n",
    "test_iterator = Iterator(test_dataset, de_vocab, en_vocab, batch_size=128, max_len=32, drop_reminder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b02151b2-a0f0-4035-896c-7c2204775036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                                                                                                                   | 0/226 [00:00<?, ?it/s][WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.880.748 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.880.999 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.881.224 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.881.448 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.881.671 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.881.893 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.882.116 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.882.343 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.882.550 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.882.757 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.882.964 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.883.172 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.883.380 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.883.619 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.883.848 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.884.077 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.884.308 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.884.535 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.884.806 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.885.017 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.885.226 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.885.435 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.885.641 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.885.849 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.886.095 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.886.303 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.886.511 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.886.719 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.886.929 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.887.138 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] CORE(61708,7f09c60eb740,python):2022-05-01-07:58:53.887.398 [mindspore/core/ir/anf_extends.cc:66] fullname_with_scope] Input 0 of cnode is not a value node, its type is CNode.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.224 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.253 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.269 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.284 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.300 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.315 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.332 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.347 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.363 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.379 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.394 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.410 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.430 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.446 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.462 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.476 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.500 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.516 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.547 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.563 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.579 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.595 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.612 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.627 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.644 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.659 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.676 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.692 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.708 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.725 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] KERNEL(61708,7f09c60eb740,python):2022-05-01-07:58:54.319.741 [mindspore/ccsrc/backend/kernel_compiler/gpu/gpu_kernel_factory.cc:96] ReducePrecision] Kernel [UniformReal] does not support int64, cast input 0 to int32.\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.385.780 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.385.820 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.385.848 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.385.874 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.385.918 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.385.946 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.385.975 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.004 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.032 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.060 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.089 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.118 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.145 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.174 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.200 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.228 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.254 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.282 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.313 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.340 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.368 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.395 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.422 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.450 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.477 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.505 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.535 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.562 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.588 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.616 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "[WARNING] PRE_ACT(61708,7f09c60eb740,python):2022-05-01-07:58:54.386.644 [mindspore/ccsrc/backend/optimizer/gpu/reduce_precision_fusion.cc:83] Run] Reduce precision for [UniformReal] input 0\n",
      "Epoch 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 226/226 [01:04<00:00,  3.50it/s, loss=4.9]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:11<00:00,  1.41s/it, loss=4.72]\n",
      "Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 226/226 [00:44<00:00,  5.09it/s, loss=3.87]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 13.82it/s, loss=4]\n",
      "Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 226/226 [00:44<00:00,  5.07it/s, loss=3.19]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 14.13it/s, loss=3.68]\n",
      "Epoch 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 226/226 [00:44<00:00,  5.10it/s, loss=2.74]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 14.05it/s, loss=3.5]\n",
      "Epoch 4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 226/226 [00:44<00:00,  5.05it/s, loss=2.43]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 13.93it/s, loss=3.37]\n",
      "Epoch 5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 226/226 [00:44<00:00,  5.06it/s, loss=2.16]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 14.11it/s, loss=3.34]\n",
      "Epoch 6: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 226/226 [00:44<00:00,  5.05it/s, loss=1.93]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 13.95it/s, loss=3.36]\n",
      "Epoch 7: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 226/226 [00:44<00:00,  5.09it/s, loss=1.73]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 13.50it/s, loss=3.38]\n",
      "Epoch 8: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 226/226 [00:44<00:00,  5.07it/s, loss=1.58]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 13.71it/s, loss=3.42]\n",
      "Epoch 9: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 226/226 [00:44<00:00,  5.06it/s, loss=1.46]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 14.00it/s, loss=3.51]\n"
     ]
    }
   ],
   "source": [
    "from mindspore import save_checkpoint, context\n",
    "# context.set_context(mode=context.PYNATIVE_MODE)\n",
    "num_epochs = 10\n",
    "best_valid_loss = float('inf')\n",
    "ckpt_file_name = os.path.join(cache_dir, 'seq2seq.ckpt')\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    train_one_step(trainer, train_iterator, i)\n",
    "    valid_loss = evaluate(model_with_loss, valid_iterator)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        save_checkpoint(model, ckpt_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e91dd45-0c21-47f4-8db5-3d73b520ccb9",
   "metadata": {},
   "source": [
    "## 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b59f27d-cdfc-4254-ac10-273f6a0ba4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, de_vocab, en_vocab, model, max_len=32):\n",
    "    model.set_train(False)\n",
    "    if isinstance(sentence, str):\n",
    "        spacy_lang = spacy.load('de')\n",
    "        tokens = [token.text.lower() for token in spacy_lang(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "    \n",
    "    if len(tokens) > max_len - 2:\n",
    "        src_len = max_len\n",
    "        tokens = ['<bos>'] + tokens[:max_len - 2] + ['<eos>']\n",
    "    else:\n",
    "        src_len = len(tokens) + 2\n",
    "        tokens = ['<bos>'] + tokens + ['<eos>'] + ['<pad>'] * (max_len - src_len)\n",
    "        \n",
    "    src = de_vocab.encode(tokens)\n",
    "    src = mindspore.Tensor(src, mindspore.int32).expand_dims(1)\n",
    "    src_len = mindspore.Tensor([src_len], mindspore.int32)\n",
    "    trg = mindspore.Tensor([en_vocab.bos_idx], mindspore.int32).expand_dims(1)\n",
    "\n",
    "    outputs = model(src, src_len, trg, max_len)\n",
    "    trg_indexes = [int(i.argmax(1).asnumpy()) for i in outputs]\n",
    "    eos_idx = trg_indexes.index(en_vocab.eos_idx) if en_vocab.eos_idx in trg_indexes else -1\n",
    "    trg_tokens = en_vocab.decode(trg_indexes[:eos_idx])\n",
    "    \n",
    "    return trg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "003ae814-d9f6-4038-87bf-d485c72a1ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "\n",
    "param_dict = load_checkpoint(ckpt_file_name)\n",
    "load_param_into_net(model, param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d326c23-de91-482a-aec5-3e3e0fe5f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss = evaluate(model_with_loss, test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff1063bc-9581-4d8d-bc15-988d120d9827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['ein', 'mann', 'mit', 'einem', 'orangefarbenen', 'hut', ',', 'der', 'etwas', 'anstarrt', '.']\n",
      "trg = ['a', 'man', 'in', 'an', 'orange', 'hat', 'starring', 'at', 'something', '.']\n"
     ]
    }
   ],
   "source": [
    "example_idx = 0\n",
    "\n",
    "src = test_dataset[example_idx][0]\n",
    "trg = test_dataset[example_idx][1]\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8d8ceab-8efd-4ef8-8024-22ba481fe570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted trg = ['a', 'man', 'in', 'an', 'orange', 'hat', ',', 'is', '<unk>', '.']\n"
     ]
    }
   ],
   "source": [
    "translation = translate_sentence(src, de_vocab, en_vocab, model)\n",
    "\n",
    "print(f'predicted trg = {translation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7119b9-a461-4df6-baea-5417440d49a7",
   "metadata": {},
   "source": [
    "### BLEU得分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d2d7d3-4177-467a-8c38-4f3121d442ed",
   "metadata": {},
   "source": [
    "> pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7af2ba16-68ae-46bb-8823-190e7b9f18b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def calculate_bleu(dataset, de_vocab, en_vocab, model, max_len=50):\n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "    \n",
    "    for data in dataset:\n",
    "        \n",
    "        src = data[0]\n",
    "        trg = data[1]\n",
    "        \n",
    "        pred_trg = translate_sentence(src, de_vocab, en_vocab, model, max_len)\n",
    "                \n",
    "        pred_trgs.append(pred_trg)\n",
    "        trgs.append([trg])\n",
    "        \n",
    "    return corpus_bleu(trgs, pred_trgs)\n",
    "    # return bleu_score(pred_trgs, trgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca63da44-0a15-425d-8f40-83f930bcd0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score = 30.40\n"
     ]
    }
   ],
   "source": [
    "bleu_score = calculate_bleu(test_dataset, de_vocab, en_vocab, model)\n",
    "\n",
    "print(f'BLEU score = {bleu_score*100:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
